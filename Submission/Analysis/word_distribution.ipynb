{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'word_distribution/'\n",
    "\n",
    "icd_org_bow_path = 'icd_org_bow_dict.pkl'\n",
    "icd_gen_bow_path = 'icd_gen_bow_dict.pkl'\n",
    "phenotyping_org_bow_path = 'phenotyping_org_bow_dict.pkl'\n",
    "phenotyping_gen_bow_path = 'phenotyping_gen_bow_dict.pkl'\n",
    "readmission_org_bow_path = 'readmission_org_bow_dict.pkl'\n",
    "readmission_gen_bow_path = 'readmission_gen_bow_dict.pkl'\n",
    "\n",
    "icd_org_dict_path = 'icd_org_dict_dict.pkl'\n",
    "icd_gen_dict_path = 'icd_gen_dict_dict.pkl'\n",
    "phenotyping_org_dict_path = 'phenotyping_org_dict_dict.pkl'\n",
    "phenotyping_gen_dict_path = 'phenotyping_gen_dict_dict.pkl'\n",
    "readmission_org_dict_path = 'readmission_org_dict_dict.pkl'\n",
    "readmission_gen_dict_path = 'readmission_gen_dict_dict.pkl'\n",
    "\n",
    "\n",
    "icd_org_bow = pickle.load(open(data_dir + icd_org_bow_path, 'rb'))\n",
    "icd_gen_bow = pickle.load(open(data_dir + icd_gen_bow_path, 'rb'))\n",
    "phenotyping_org_bow = pickle.load(open(data_dir + phenotyping_org_bow_path, 'rb'))\n",
    "phenotyping_gen_bow = pickle.load(open(data_dir + phenotyping_gen_bow_path, 'rb'))\n",
    "readmission_org_bow = pickle.load(open(data_dir + readmission_org_bow_path, 'rb'))\n",
    "readmission_gen_bow = pickle.load(open(data_dir + readmission_gen_bow_path, 'rb'))\n",
    "\n",
    "icd_org_dict = pickle.load(open(data_dir + icd_org_dict_path, 'rb'))\n",
    "icd_gen_dict = pickle.load(open(data_dir + icd_gen_dict_path, 'rb'))\n",
    "phenotyping_org_dict = pickle.load(open(data_dir + phenotyping_org_dict_path, 'rb'))\n",
    "phenotyping_gen_dict = pickle.load(open(data_dir + phenotyping_gen_dict_path, 'rb'))\n",
    "readmission_org_dict = pickle.load(open(data_dir + readmission_org_dict_path, 'rb'))\n",
    "readmission_gen_dict = pickle.load(open(data_dir + readmission_gen_dict_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_words(bow_dict, dict_dict, k):\n",
    "    top_k_words = {}\n",
    "\n",
    "    for cls, bow in bow_dict.items():\n",
    "        dictionary = dict_dict[cls]\n",
    "        \n",
    "        # Convert BoW (list of (word_id, frequency)) into word and frequency\n",
    "        word_freq = [(dictionary[word_id], freq) for word_id, freq in bow]\n",
    "        \n",
    "        # Sort by frequency in descending order\n",
    "        sorted_word_freq = sorted(word_freq, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select the top k most frequent words\n",
    "        top_k_words[cls] = sorted_word_freq[:k]\n",
    "\n",
    "    return top_k_words\n",
    "\n",
    "\n",
    "def filter_common_words(bow_dict, dict_dict):\n",
    "    # Step 1: Extract words from all classes\n",
    "    class_words = {}\n",
    "    \n",
    "    for cls, dictionary in dict_dict.items():\n",
    "        # Get all words from the dictionary for the class\n",
    "        class_words[cls] = set(dictionary.values())  # `dictionary.values()` gives all the words\n",
    "    \n",
    "    # Step 2: Find intersection of words across all classes\n",
    "    common_words = set.intersection(*class_words.values())  # Intersection of all class word sets\n",
    "\n",
    "    # Step 3: Filter out common words from BoW for each class\n",
    "    filtered_bow_dict = {}\n",
    "    \n",
    "    for cls, bow in bow_dict.items():\n",
    "        dictionary = dict_dict[cls]\n",
    "        \n",
    "        # Filter out common words from the BoW\n",
    "        filtered_bow = [(word_id, freq) for word_id, freq in bow if dictionary[word_id] not in common_words]\n",
    "        filtered_bow_dict[cls] = filtered_bow\n",
    "\n",
    "    return filtered_bow_dict, common_words\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_entropy(top_k_words):\n",
    "    entropy_dict = {}\n",
    "\n",
    "    for cls, word_freq_list in top_k_words.items():\n",
    "        # Get the frequencies of the top k words\n",
    "        frequencies = np.array([freq for _, freq in word_freq_list], dtype=np.float32)\n",
    "        \n",
    "        # Normalize the frequencies to get probabilities\n",
    "        total_freq = np.sum(frequencies)\n",
    "        probabilities = frequencies / total_freq\n",
    "        \n",
    "        # Calculate entropy using the formula H = -sum(p * log(p))\n",
    "        entropy = -np.sum(probabilities * np.log(probabilities + 1e-10))  # Added small value to avoid log(0)\n",
    "        \n",
    "        # Store the entropy for the current class\n",
    "        entropy_dict[cls] = entropy\n",
    "\n",
    "    return entropy_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_difference(entropy_dict_1, entropy_dict_2):\n",
    "    # Initialize a dictionary to hold the differences\n",
    "    entropy_difference = {}\n",
    "\n",
    "    # Ensure both dictionaries have the same classes\n",
    "    classes = sorted(set(entropy_dict_1.keys()).union(set(entropy_dict_2.keys())))\n",
    "\n",
    "    # Calculate the differences\n",
    "    for cls in classes:\n",
    "        value_1 = entropy_dict_1.get(cls, 0)  # Default to 0 if class not in dict_1\n",
    "        value_2 = entropy_dict_2.get(cls, 0)  # Default to 0 if class not in dict_2\n",
    "        entropy_difference[cls] = value_2 - value_1  # Calculate the difference (dict_2 - dict_1)\n",
    "\n",
    "    return entropy_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_three_entropy_dictionaries(entropy_dict_1, entropy_dict_2, entropy_dict_3):\n",
    "    \"\"\"\n",
    "    Plots three entropy dictionaries in the same figure with different colors.\n",
    "\n",
    "    Parameters:\n",
    "        entropy_dict_1 (dict): The first entropy dictionary.\n",
    "        entropy_dict_2 (dict): The second entropy dictionary.\n",
    "        entropy_dict_3 (dict): The third entropy dictionary.\n",
    "    \"\"\"\n",
    "    # Ensure all dictionaries have the same classes\n",
    "    classes = sorted(set(entropy_dict_1.keys()).union(entropy_dict_2.keys()).union(entropy_dict_3.keys()))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    values_1 = [entropy_dict_1.get(cls, 0) for cls in classes]\n",
    "    values_2 = [entropy_dict_2.get(cls, 0) for cls in classes]\n",
    "    values_3 = [entropy_dict_3.get(cls, 0) for cls in classes]\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plotting each dictionary\n",
    "    bar_width = 0.25\n",
    "    x = range(len(classes))\n",
    "    \n",
    "    # Plot each entropy dictionary as a bar\n",
    "    plt.bar([i - bar_width for i in x], values_1, width=bar_width, label='Entropy Dict 1', color='skyblue')\n",
    "    plt.bar(x, values_2, width=bar_width, label='Entropy Dict 2', color='salmon')\n",
    "    plt.bar([i + bar_width for i in x], values_3, width=bar_width, label='Entropy Dict 3', color='lightgreen')\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Entropy Value')\n",
    "    plt.title('Comparison of Entropy Values Across Three Dictionaries')\n",
    "    \n",
    "    # Adding ticks and grid\n",
    "    plt.xticks(x, classes)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have three entropy dictionaries\n",
    "# entropy_dict_1 = {0: 1.5, 1: 1.2, 2: 0.8}\n",
    "# entropy_dict_2 = {0: 2.0, 1: 0.5, 2: 1.0}\n",
    "# entropy_dict_3 = {0: 1.8, 1: 0.9, 2: 1.3}\n",
    "\n",
    "# plot_three_entropy_dictionaries(entropy_dict_1, entropy_dict_2, entropy_dict_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_org_dict_filtered, common_words = filter_common_words(icd_org_bow, icd_org_dict)\n",
    "icd_org_top_k_words = get_top_k_words(icd_org_dict_filtered, icd_org_dict, 1000)\n",
    "icd_org_entropy = calculate_entropy(icd_org_top_k_words)\n",
    "icd_gen_dict_filtered, common_words = filter_common_words(icd_gen_bow, icd_gen_dict)\n",
    "icd_gen_top_k_words = get_top_k_words(icd_gen_dict_filtered, icd_gen_dict, 1000)\n",
    "icd_gen_entropy = calculate_entropy(icd_gen_top_k_words)\n",
    "\n",
    "phenotyping_gen_bow_filtered, common_words = filter_common_words(phenotyping_gen_bow, phenotyping_gen_dict)\n",
    "phenotyping_gen_top_k_words = get_top_k_words(phenotyping_gen_bow_filtered, phenotyping_gen_dict, 1000)\n",
    "phenotyping_gen_entropy = calculate_entropy(phenotyping_gen_top_k_words)\n",
    "phenotyping_org_bow_filtered, common_words = filter_common_words(phenotyping_org_bow, phenotyping_org_dict)\n",
    "phenotyping_org_top_k_words = get_top_k_words(phenotyping_org_bow_filtered, phenotyping_org_dict, 1000)\n",
    "phenotyping_org_entropy = calculate_entropy(phenotyping_org_top_k_words)\n",
    "\n",
    "readmission_org_bow_filtered, common_words = filter_common_words(readmission_org_bow, readmission_org_dict)\n",
    "readmission_org_top_k_words = get_top_k_words(readmission_org_bow_filtered, readmission_org_dict, 1000)\n",
    "readmission_org_entropy = calculate_entropy(readmission_org_top_k_words)\n",
    "readmission_gen_bow_filtered, common_words = filter_common_words(readmission_gen_bow, readmission_gen_dict)\n",
    "readmission_gen_top_k_words = get_top_k_words(readmission_gen_bow_filtered, readmission_gen_dict, 1000)\n",
    "readmission_gen_entropy = calculate_entropy(readmission_gen_top_k_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotyping_gen_top_k_words[0]\n",
    "\n",
    "# make wordcloud from this list\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def plot_wordcloud(word_freq_list, title):\n",
    "    # Initialize the WordCloud object\n",
    "    wc = WordCloud(width=800, height=400, max_words=200, background_color='white')\n",
    "    \n",
    "    # Generate the word cloud\n",
    "    wc.generate_from_frequencies(dict(word_freq_list))\n",
    "    \n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "#plot_wordcloud(phenotyping_gen_top_k_words[0], 'Phenotyping General Top 1000 Words')\n",
    "#plot_wordcloud(phenotyping_gen_top_k_words[1], 'Phenotyping General Top 1000 Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dict_path = '../Anonymization/negated_test_final_normalized_dict.pkl'\n",
    "with open(dict_path, 'rb') as f:\n",
    "    normalized_dict = pickle.load(f)\n",
    "\n",
    "# count the number of words in org_dict for each class\n",
    "# where the word is in normalized_dict.keys()\n",
    "# and the normlized_dict[word] is in gen_dict\n",
    "# or missing from gen_dict\n",
    "\n",
    "def get_entity_difference(org_dict, gen_dict, normalized_dict):\n",
    "    # lower case everything in normalized_dict\n",
    "    #normalized_dict = {k.lower(): v.lower() for k, v in normalized_dict.items()}\n",
    "    entity_diff = {}\n",
    "    \n",
    "    for cls, dictionary in org_dict.items():\n",
    "        org_set = set(dictionary.values())\n",
    "        gen_set = set(gen_dict[cls].values())\n",
    "        org_ent = []\n",
    "        for word in org_set:\n",
    "            if word in normalized_dict.keys():\n",
    "                org_ent.append(word)\n",
    "        gen_ent = []\n",
    "        for word in gen_set:\n",
    "            if word in normalized_dict.keys():\n",
    "                gen_ent.append(word)\n",
    "        \"\"\"\n",
    "        diff_set = org_set - gen_set\n",
    "        for word in list(diff_set):\n",
    "            if word in normalized_dict.keys():\n",
    "                if normalized_dict[word] in gen_set:\n",
    "                    if cls not in entity_diff:\n",
    "                        entity_diff[cls] = [word]\n",
    "                    else:\n",
    "                        entity_diff[cls].append(word)\n",
    "                else:\n",
    "                    if cls not in entity_diff:\n",
    "                        entity_diff[cls] = [\"<not-exist>\"]\n",
    "                    else:\n",
    "                        entity_diff[cls].append(\"<not-exist>\")\n",
    "        \"\"\"\n",
    "        entity_diff[cls] = len(gen_set) / len(org_set)\n",
    "    return entity_diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"10 screws', '\"4', '\"93% blockage\"', '\"abdominal\" cancer', '\"abnormal looking', '\"adverse rxn\".', '\"agonal', '\"agonal breathing\"', '\"agonal breathing.\"', '\"alcoholic coma\"', '\"allergy pills\",', '\"almost black\"', '\"altered\"', '\"anti-inflammatory effect\".', '\"antibiotics,\"', '\"arteriosclerosis\"', '\"arthritis,\"', '\"asthma', '\"asthma\" symptoms', '\"babbling\"', '\"back problems\"', '\"back to back\"', '\"bad\" taste in', '\"balance disorder/falls\"),', '\"barrett\\'s\"', '\"basal ganglia\" hemorrhage on the left.', '\"benign bladder lesions\"', '\"bigeminy\"', '\"black', '\"black stools\"', '\"blacking out\"', '\"bladder medication\"', '\"bladder sling\"', '\"bloating.\"', '\"blocked neck artery\"', '\"blood clots.\"', '\"blood\" cancer', '\"blood\" labs', '\"blood\",', '\"blooming\"', '\"blooming\" susceptibility', '\"blue toes\".', '\"bone cancer\"', '\"bone on bone\"', '\"bone spurs\"', '\"bone\"', '\"bowel problem\"', '\"brain tumor\",', '\"breathing', '\"breathing problems\"', '\"breathing treatments,\"', '\"bright\\'s disease\"', '\"broken', '\"bronchitis\"', '\"bubbling\"', '\"bucking\" event', '\"burning\" chest tightness.', '\"burning\" pain', '\"cad\"', '\"cancer\"', '\"cancers.\"', '\"cardiac disease\",', '\"cardioversion\"', '\"castleman\\'s syndrome\"', '\"cell abnormality\"', '\"central fever,\"', '\"changes\"', '\"cherry coke\" colored fluid return', '\"chest', '\"chest congestion\"', '\"chest pain,\"', '\"chills\"', '\"chronic\" lll changes', '\"circulation problems.\"', '\"cirrhosis\"', '\"clogged port a cath\"', '\"clot\"', '\"clots\"', '\"coffee ground\"', '\"cold symptoms\".', '\"cold/pharyngitis\").', '\"colitis\",', '\"collagen vascular disease panel\",', '\"coma', '\"compaction and', '\"complex partial with', '\"confusion\"', '\"confusion/disorientation\"', '\"congested\",', '\"cortical', '\"costochondritic chest pain\"', '\"cough,', '\"coumadin\"', '\"cpap\"', '\"crack\" lung', '\"crazy paving\".', '\"creepy crawlies.\"', '\"crisis\"', '\"critical\" spinal canal stenosis.', '\"cutting\"']\n"
     ]
    }
   ],
   "source": [
    "print(list(normalized_dict.keys())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_entity_diff = get_entity_difference(icd_org_dict, icd_gen_dict, normalized_dict)\n",
    "phenotyping_entity_diff = get_entity_difference(phenotyping_org_dict, phenotyping_gen_dict, normalized_dict)\n",
    "readmission_entity_diff = get_entity_difference(readmission_org_dict, readmission_gen_dict, normalized_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6297347316471315, 1: 0.6204670813284826}\n",
      "{0: 0.6136229022704837, 1: 0.5755946225439503, 2: 0.52963841138115, 3: 0.5385674931129476, 4: 0.536134903640257, 5: 0.5572755417956656, 6: 0.5452205882352941, 7: 0.5136887608069164, 8: 0.5313161875945537, 9: 0.5899705014749262, 10: 0.5775460394941203, 11: 0.5904696132596685, 12: 0.6107360977177756, 13: 0.5402697495183044, 14: 0.5535045478865703, 15: 0.5405059237912264, 16: 0.5023458445040214, 17: 0.5791814946619217, 18: 0.582235153174739, 19: 0.573780305297815, 20: 0.6308695652173913, 21: 0.5056448853917208, 22: 0.5627212948912493, 23: 0.5312393308296347, 24: 0.5224568138195778, 25: 0.5416403785488959, 26: 0.5784916837548416, 27: 0.5907713819622465, 28: 0.5120288692862871, 29: 0.6734955185659411, 30: 0.5542384254081861, 31: 0.6005967604433078, 32: 0.5546659304251794, 33: 0.6067608044501498, 34: 0.6057233704292527, 35: 0.5759233926128591, 36: 0.6023160363529757, 37: 0.47693452380952384, 38: 0.5475940323597395, 39: 0.6641666666666667, 40: 0.5701158609668397, 41: 0.5190791548407443, 42: 0.5376712328767124, 43: 0.5523096129837702, 44: 0.5770065075921909, 45: 0.488962472406181, 46: 0.5710045662100457, 47: 0.5336094297546989, 48: 0.5640934844192634, 49: 0.5159456899273761}\n",
      "{0: 0.40926225094238017, 1: 0.4138817480719794, 2: 0.42353723404255317, 3: 0.4183504471679364, 4: 0.46494992846924177, 5: 0.4719600222098834, 6: 0.4707585408222351, 7: 0.4591136079900125, 8: 0.44716913090515686, 9: 0.44113263785394935}\n"
     ]
    }
   ],
   "source": [
    "print(readmission_entity_diff)\n",
    "print(icd_entity_diff)\n",
    "print(phenotyping_entity_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               avg    std    max    min\n",
      "ICD          0.561  0.040  0.673  0.477\n",
      "Phenotyping  0.442  0.023  0.472  0.409\n",
      "Readmission  0.625  0.005  0.630  0.620\n"
     ]
    }
   ],
   "source": [
    "# take the average of missing entities percent for each dataset\n",
    "icd_entity_diff_avg = np.mean(list(icd_entity_diff.values()))\n",
    "phenotyping_entity_diff_avg = np.mean(list(phenotyping_entity_diff.values()))\n",
    "readmission_entity_diff_avg = np.mean(list(readmission_entity_diff.values()))\n",
    "\n",
    "# std\n",
    "icd_entity_diff_std = np.std(list(icd_entity_diff.values()))\n",
    "phenotyping_entity_diff_std = np.std(list(phenotyping_entity_diff.values()))\n",
    "readmission_entity_diff_std = np.std(list(readmission_entity_diff.values()))\n",
    "\n",
    "# max and min\n",
    "\n",
    "icd_entity_diff_max = np.max(list(icd_entity_diff.values()))\n",
    "phenotyping_entity_diff_max = np.max(list(phenotyping_entity_diff.values()))\n",
    "readmission_entity_diff_max = np.max(list(readmission_entity_diff.values()))\n",
    "\n",
    "icd_entity_diff_min = np.min(list(icd_entity_diff.values()))\n",
    "phenotyping_entity_diff_min = np.min(list(phenotyping_entity_diff.values()))\n",
    "readmission_entity_diff_min = np.min(list(readmission_entity_diff.values()))\n",
    "\n",
    "icd_ent_diff = {\"avg\": icd_entity_diff_avg, \"std\": icd_entity_diff_std, \"max\": icd_entity_diff_max, \"min\": icd_entity_diff_min}\n",
    "phenotyping_ent_diff = {\"avg\": phenotyping_entity_diff_avg, \"std\": phenotyping_entity_diff_std, \"max\": phenotyping_entity_diff_max, \"min\": phenotyping_entity_diff_min}\n",
    "readmission_ent_diff = {\"avg\": readmission_entity_diff_avg, \"std\": readmission_entity_diff_std, \"max\": readmission_entity_diff_max, \"min\": readmission_entity_diff_min}\n",
    "\n",
    "# to df\n",
    "import pandas as pd\n",
    "\n",
    "icd_ent_diff_df = pd.DataFrame(icd_ent_diff, index=[\"ICD\"])\n",
    "phenotyping_ent_diff_df = pd.DataFrame(phenotyping_ent_diff, index=[\"Phenotyping\"])\n",
    "readmission_ent_diff_df = pd.DataFrame(readmission_ent_diff, index=[\"Readmission\"])\n",
    "\n",
    "# concat\n",
    "\n",
    "ent_diff_df = pd.concat([icd_ent_diff_df, phenotyping_ent_diff_df, readmission_ent_diff_df])\n",
    "\n",
    "# round to 3 decimal places\n",
    "ent_diff_df = ent_diff_df.round(3)\n",
    "\n",
    "# to csv\n",
    "ent_diff_df.to_csv(\"entity_diff.csv\")\n",
    "\n",
    "print(ent_diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: -1.062892, 1: -1.1040044, 2: -0.9743438, 3: -0.18843985, 4: -0.6823597, 5: -0.06401539, 6: -0.69732237, 7: -0.08685303, 8: -0.25134325, 9: -0.26688766}\n",
      "{0: 0.40926225094238017, 1: 0.4138817480719794, 2: 0.42353723404255317, 3: 0.4183504471679364, 4: 0.46494992846924177, 5: 0.4719600222098834, 6: 0.4707585408222351, 7: 0.4591136079900125, 8: 0.44716913090515686, 9: 0.44113263785394935}\n"
     ]
    }
   ],
   "source": [
    "icd_entropy_diff = calculate_entropy_difference(icd_org_entropy, icd_gen_entropy)\n",
    "phenotyping_entropy_diff = calculate_entropy_difference(phenotyping_org_entropy, phenotyping_gen_entropy)\n",
    "readmission_entropy_diff = calculate_entropy_difference(readmission_org_entropy, readmission_gen_entropy)\n",
    "\n",
    "\n",
    "print(phenotyping_entropy_diff)\n",
    "print(phenotyping_entity_diff)\n",
    "\n",
    "# number of classes\n",
    "icd_cls_num = len(icd_entropy_diff)\n",
    "phenotyping_cls_num = len(phenotyping_entropy_diff)\n",
    "readmission_cls_num = len(readmission_entropy_diff)\n",
    "\n",
    "# average difference\n",
    "icd_ave_diff = np.mean(list(icd_entropy_diff.values()))\n",
    "phenotyping_ave_diff = np.mean(list(phenotyping_entropy_diff.values()))\n",
    "readmission_ave_diff = np.mean(list(readmission_entropy_diff.values()))\n",
    "\n",
    "# the number of positive classes\n",
    "icd_pos_num = len([1 for v in icd_entropy_diff.values() if v > 0])\n",
    "phenotyping_pos_num = len([1 for v in phenotyping_entropy_diff.values() if v > 0])\n",
    "readmission_pos_num = len([1 for v in readmission_entropy_diff.values() if v > 0])\n",
    "# percentage\n",
    "icd_pos_per = icd_pos_num / len(icd_entropy_diff)*100\n",
    "phenotyping_pos_per = phenotyping_pos_num / len(phenotyping_entropy_diff)*100\n",
    "readmission_pos_per = readmission_pos_num / len(readmission_entropy_diff)*100\n",
    "\n",
    "# to df where each column is different stats and each row is different dataset\n",
    "import pandas as pd\n",
    "\n",
    "stats_dict = {}\n",
    "stats_dict['Dataset'] = ['readmission','icd', 'phenotyping']\n",
    "stats_dict['Dataset'] = ['readmission','icd', 'phenotyping']\n",
    "stats_dict['Number of Classes'] = [readmission_cls_num, icd_cls_num, phenotyping_cls_num]\n",
    "stats_dict['Average Difference'] = [readmission_ave_diff, icd_ave_diff, phenotyping_ave_diff]\n",
    "stats_dict['Positive Class Number'] = [f'{readmission_pos_num} ({readmission_pos_per:.2f})', f'{icd_pos_num} ({icd_pos_per:.2f})', f'{phenotyping_pos_num} ({phenotyping_pos_per:.2f})']\n",
    "stats_dict['Entity Difference'] = [readmission_entity_diff_avg, icd_entity_diff_avg, phenotyping_entity_diff_avg]\n",
    "stats_df = pd.DataFrame(stats_dict)\n",
    "# round to 3 decimal places\n",
    "stats_df = stats_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Number of Classes</th>\n",
       "      <th>Average Difference</th>\n",
       "      <th>Positive Class Number</th>\n",
       "      <th>Entity Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>readmission</td>\n",
       "      <td>2</td>\n",
       "      <td>0.446</td>\n",
       "      <td>2 (100.00)</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>icd</td>\n",
       "      <td>50</td>\n",
       "      <td>0.020</td>\n",
       "      <td>36 (72.00)</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phenotyping</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0 (0.00)</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset  Number of Classes  Average Difference Positive Class Number  \\\n",
       "0  readmission                  2               0.446            2 (100.00)   \n",
       "1          icd                 50               0.020            36 (72.00)   \n",
       "2  phenotyping                 10              -0.538              0 (0.00)   \n",
       "\n",
       "   Entity Difference  \n",
       "0              0.625  \n",
       "1              0.561  \n",
       "2              0.442  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "stats_df.to_csv('dataset_stats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1.1040044\n"
     ]
    }
   ],
   "source": [
    "# argmin of phenotyping_entropy_diff\n",
    "min_key = min(phenotyping_entropy_diff, key=phenotyping_entropy_diff.get)\n",
    "print(min_key, phenotyping_entropy_diff[min_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -1.062892,\n",
       " 1: -1.1040044,\n",
       " 2: -0.9743438,\n",
       " 3: -0.18843985,\n",
       " 4: -0.6823597,\n",
       " 5: -0.06401539,\n",
       " 6: -0.69732237,\n",
       " 7: -0.08685303,\n",
       " 8: -0.25134325,\n",
       " 9: -0.26688766}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenotyping_entropy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n['advanced_cancer',\\n 'obesity',\\n 'advanced_lung_disease',\\n 'chronic_pain_fibromyalgia',\\n 'alcohol_abuse',\\n 'depression',\\n 'other_substance_abuse',\\n 'chronic_neurological_dystrophies',\\n 'schizophrenia_and_other_psychiatric_disorders',\\n 'advanced_heart_disease']\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "['advanced_cancer',\n",
    " 'obesity',\n",
    " 'advanced_lung_disease',\n",
    " 'chronic_pain_fibromyalgia',\n",
    " 'alcohol_abuse',\n",
    " 'depression',\n",
    " 'other_substance_abuse',\n",
    " 'chronic_neurological_dystrophies',\n",
    " 'schizophrenia_and_other_psychiatric_disorders',\n",
    " 'advanced_heart_disease']\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
